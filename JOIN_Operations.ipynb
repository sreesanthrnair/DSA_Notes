{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMx4hIqc+rAhdiOS5WU6qU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreesanthrnair/DSA_Notes/blob/main/JOIN_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##  1. JOIN Operations\n",
        "\n",
        "Joins combine rows from two or more tables based on a related column.\n",
        "\n",
        "###  Types of Joins\n",
        "\n",
        "| Join Type     | Description | Example |\n",
        "|---------------|-------------|---------|\n",
        "| **Inner Join** | Returns matching rows from both tables | Customers with orders |\n",
        "| **Left Join**  | All rows from left + matching from right | All customers, even if no orders |\n",
        "| **Right Join** | All rows from right + matching from left | All orders, even if customer missing |\n",
        "| **Full Join**  | All rows from both tables | Combine all data, fill missing with NULL |\n",
        "| **Cross Join** | Cartesian product of both tables | Every customer with every product |\n",
        "\n",
        "###  SQL Example\n",
        "```sql\n",
        "SELECT a.name, b.order_id\n",
        "FROM customers a\n",
        "JOIN orders b ON a.customer_id = b.customer_id;\n",
        "```\n",
        "\n",
        "###  pandas Example\n",
        "```python\n",
        "pd.merge(customers, orders, on='customer_id', how='inner')\n",
        "```\n",
        "\n",
        "###  PySpark Example\n",
        "```python\n",
        "customers.join(orders, on='customer_id', how='inner')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "##  2. GROUP BY\n",
        "\n",
        "Used to aggregate data based on one or more columns.\n",
        "\n",
        "###  Common Aggregations\n",
        "- `COUNT()`\n",
        "- `SUM()`\n",
        "- `AVG()`\n",
        "- `MAX()`, `MIN()`\n",
        "\n",
        "###  SQL Example\n",
        "```sql\n",
        "SELECT region, SUM(sales) AS total_sales\n",
        "FROM orders\n",
        "GROUP BY region;\n",
        "```\n",
        "\n",
        "###  pandas Example\n",
        "```python\n",
        "orders.groupby('region')['sales'].sum().reset_index()\n",
        "```\n",
        "\n",
        "###  PySpark Example\n",
        "```python\n",
        "orders.groupBy('region').agg({'sales': 'sum'}).show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "##  3. Window Functions\n",
        "\n",
        "Window functions perform calculations across a set of rows related to the current row—without collapsing the result like `GROUP BY`.\n",
        "\n",
        "###  Use Cases\n",
        "- Ranking (e.g., `RANK()`, `DENSE_RANK()`)\n",
        "- Running totals (`SUM() OVER`)\n",
        "- Lag/Lead analysis (`LAG()`, `LEAD()`)\n",
        "\n",
        "###  SQL Example\n",
        "```sql\n",
        "SELECT name, sales,\n",
        "       RANK() OVER (PARTITION BY region ORDER BY sales DESC) AS rank\n",
        "FROM orders;\n",
        "```\n",
        "\n",
        "###  PySpark Example\n",
        "```python\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank\n",
        "\n",
        "windowSpec = Window.partitionBy(\"region\").orderBy(\"sales\")\n",
        "orders.withColumn(\"rank\", rank().over(windowSpec)).show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "##  Tips for Mastery\n",
        "\n",
        "- Use **JOIN** to enrich data, **GROUP BY** to summarize, and **WINDOW** to analyze trends or patterns.\n",
        "- In **pandas**, chaining `.groupby()` with `.agg()` or `.apply()` gives flexibility.\n",
        "- In **PySpark**, window functions are powerful for scalable analytics—especially in time-series or ranking problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "dPgeAqQPWCBu"
      }
    }
  ]
}